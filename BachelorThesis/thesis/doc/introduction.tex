\newpage
\changeindent{0cm}
\section{はじめに}
\changeindent{2cm}

近年, 人工知能に関する研究分野は目覚ましい発展を遂げており様々な分野に応用されている. その中でも人間の学習プロセスに近いとされる強化学習と深層学習を融合した深層強化学習は自動運転やロボット, 推薦システム等の実生活の問題解決への応用例が数多く報告されている \cite{Vehicle}\cite{robotics}\cite{recommendation}. 
実世界の問題解決への応用だけでなく, 深層強化学習はゲームへの応用も盛んである.
特に将棋や囲碁といった, プレイヤーが意思決定をする段階でそれ以前の意思決定の過程がすべて把握可能な完全情報ゲームへの応用においては AlphaGo \cite{AlphaGo}, AlphaZero \cite{AlphaZero} を筆頭に現役のプロプレイヤーを圧倒する性能を残しており成果が顕著である. 
最近では麻雀やポーカーのような, プレイヤーに与えられる情報が部分的である不完全情報ゲームへの応用も注目されている.
\par
本研究では不完全情報ゲームであるトレーディングカードゲーム (TCG) 環境に注目した. TCG は不完全情報ゲームの中でも使用可能なカードの性能や種類を変更可能という点で, 他のゲームよりも人工知能による攻略が困難である. また, この性質のためゲームバランスの調整が難しく, 性能を情報修正するバフや下方修正するナーフなどの用語が存在する. 以上の点を背景として, 深層強化学習と進化型計算といった工学的な手法を用いてゲームバランスを調整する手法を提案し, 独自に構築したトレーディングカードゲーム環境を用いて数値実験することでその有効性を示す. 
\par
以下に本論文の構成を示す.  まず, 2 章では本研究で用いる要素技術について, 3 章では関連研究と提案手法について説明する. 4 章で実験方法の説明をし, 5 章で実験結果と考察を示す. そして, 6 章に本研究のまとめ及び今後の課題について述べる.